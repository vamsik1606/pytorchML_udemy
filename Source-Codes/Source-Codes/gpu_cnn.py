# -*- coding: utf-8 -*-
"""GPU-CNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1f3vs_8K-vjxdYqyb99B6ooP0Ws_FLqsQ
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
import matplotlib.pyplot as plt

transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])
trainset = torchvision.datasets.CIFAR10(root = './data',train = True, download = True,transform = transform)
testset = torchvision.datasets.CIFAR10(root = './data',train = False, download = True,transform = transform)

trainloader = torch.utils.data.DataLoader(trainset,batch_size = 64, shuffle=True, num_workers = 2)
testloader = torch.utils.data.DataLoader(testset,batch_size = 64, shuffle=True, num_workers = 2)

torch.cuda.is_available()

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

from torch.nn.modules.pooling import MaxPool2d
class CNN(nn.Module):
  def __init__(self):
    super().__init__()
    self.conv = nn.Sequential(
       nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3,stride=1,padding=1),  # (i-f+2p)/s  + 1  (32-3+2)/1  +1
       nn.MaxPool2d(kernel_size=2,stride=2), # (M-P)/s + 1  (32-2)/2 + 1 = 16
       nn.ReLU(),
       nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3,stride=1,padding=1), 
       nn.MaxPool2d(kernel_size=2,stride=2),   # (M-P)/s + 1  (16-2)/2 +1  = 8
       nn.ReLU()
    )
    self.fc = nn.Sequential(
       nn.Linear(in_features=32*8*8,out_features=64),
       nn.ReLU(),
       nn.Linear(in_features=64,out_features=10)  
    )

  def forward(self,x):
    x = self.conv(x)
    x = x.view(x.size(0),-1)
    x = self.fc(x)
    return x

model = CNN().to(device)

criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(),lr = 0.01)

import time
start_time = time.time()

loss_list = []
accuracy_list = []
for epoch in range(30):
    epoch_loss = 0
    for images, labels in trainloader:
        images = images.to(device)
        labels = labels.to(device)
        outputs = model(images)
        loss = criterion(outputs, labels)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
        epoch_loss += loss.item()
    
    loss_list.append(epoch_loss / len(trainloader))

        
    with torch.no_grad():
        correct = 0
        total = 0
        for images, labels in trainloader:
            images = images.to(device)
            labels = labels.to(device)
            outputs = model(images)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
            accuracy = correct / total
            accuracy_list.append(accuracy)

        print("Epoch [{}/30] Training Accuracy: {:.4f}".format(epoch + 1, correct / total),"Loss: {:.4f}".format(loss_list[-1]))

print("Training took {:.2f} seconds".format(time.time() - start_time))

with torch.no_grad():
  correct = 0 
  total = 0
  for images, labels in testloader:
    images = images.to(device)
    labels = labels.to(device)
    outputs = model(images)
    _,predicted = torch.max(outputs.data,1)
    total += labels.size(0)
    correct += (predicted == labels).sum().item()
  print('Test Accuracy: {:.4f}'.format(correct/total))

save_state = {'model':model.state_dict(), 'optimizer':optimizer.state_dict()}
torch.save(save_state, 'CNN_GPU.pth')

state = torch.load('CNN_GPU.pth')
model.load_state_dict(state['model'])
optimizer.load_state_dict(state['optimizer'])

with torch.no_grad():
  correct = 0 
  total = 0
  for images, labels in testloader:
    images = images.to(device)
    labels = labels.to(device)
    outputs = model(images)
    _,predicted = torch.max(outputs.data,1)
    total += labels.size(0)
    correct += (predicted == labels).sum().item()
  print('Test Accuracy: {:.4f}'.format(correct/total))