# -*- coding: utf-8 -*-
"""CNN_Image_Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VsnI0RKaZQfk8XbcZn0fWRbsM1Om5LKs
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
import matplotlib.pyplot as plt

transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])
trainset = torchvision.datasets.CIFAR10(root = './data',train = True, download = True,transform = transform)
testset = torchvision.datasets.CIFAR10(root = './data',train = False, download = True,transform = transform)

trainset[0]

trainloader = torch.utils.data.DataLoader(trainset,batch_size = 64, shuffle=True, num_workers = 2)
testloader = torch.utils.data.DataLoader(testset,batch_size = 64, shuffle=True, num_workers = 2)

image,label = trainset[0]
print('Shape:',image.shape, '\Label:',label)

"""**Creating the Network**"""

from torch.nn.modules.pooling import MaxPool2d
class CNN(nn.Module):
  def __init__(self):
    super().__init__()
    self.conv = nn.Sequential(
       nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3,stride=1,padding=1),  # (i-f+2p)/s  + 1  (32-3+2)/1  +1
       nn.MaxPool2d(kernel_size=2,stride=2), # (M-P)/s + 1  (32-2)/2 + 1 = 16
       nn.ReLU(),
       nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3,stride=1,padding=1), 
       nn.MaxPool2d(kernel_size=2,stride=2),   # (M-P)/s + 1  (16-2)/2 +1  = 8
       nn.ReLU()
    )
    self.fc = nn.Sequential(
       nn.Linear(in_features=32*8*8,out_features=64),
       nn.ReLU(),
       nn.Linear(in_features=64,out_features=10)  
    )

  def forward(self,x):
    x = self.conv(x)
    x = x.view(x.size(0),-1)
    x = self.fc(x)
    return x

model = CNN()

criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(),lr = 0.01)

"""**Training**"""

import time
start_time = time.time()

loss_list = []
accuracy_list = []
for epoch in range(30):
    epoch_loss = 0
    for images, labels in trainloader:
        outputs = model(images)
        loss = criterion(outputs, labels)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
        epoch_loss += loss.item()
    
    loss_list.append(epoch_loss / len(trainloader))

        
    with torch.no_grad():
        correct = 0
        total = 0
        for images, labels in trainloader:
            outputs = model(images)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
            accuracy = correct / total
            accuracy_list.append(accuracy)

        print("Epoch [{}/30] Training Accuracy: {:.4f}".format(epoch + 1, correct / total),"Loss: {:.4f}".format(loss_list[-1]))

print("Training took {:.2f} seconds".format(time.time() - start_time))

x = range(30)
plt.plot(x,loss_list)
plt.xlabel('iterations')
plt.ylabel('loss')
plt.show()

"""**Testing**"""

with torch.no_grad():
  correct = 0 
  total = 0
  for images, labels in testloader:
    outputs = model(images)
    _,predicted = torch.max(outputs.data,1)
    total += labels.size(0)
    correct += (predicted == labels).sum().item()
  print('Test Accuracy: {:.4f}'.format(correct/total))

from sklearn.metrics import confusion_matrix

model.eval()
with torch.no_grad():
  correct = 0
  total = 0
  confusion_matrix = torch.zeros(10,10)
  for images, labels in testloader:
    outputs = model(images)
    _,predicted = torch.max(outputs.data,1)
    total += labels.size(0)
    correct += (predicted == labels).sum().item()
    for i,j in zip(predicted,labels):
      confusion_matrix[i][j] += 1
confusion_matrix = confusion_matrix.numpy().astype(int)
print('Confusion Matrix')
print(confusion_matrix)

accuracy = (confusion_matrix.diagonal().sum()/confusion_matrix.sum())*100
print(f'Accuracy: {accuracy:.2f}%')